{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613c6973-81e1-4b22-8a53-61b6c7a8ffa8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8155bb40-ebd3-467b-90a8-e8e815a147d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen abc>:106: LangGraphDeprecatedSinceV10: AgentStatePydantic has been moved to `langchain.agents`. Please update your import to `from langchain.agents import AgentStatePydantic`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# RAG & LangChain Imports\n",
    "import chromadb\n",
    "import langchain\n",
    "import langchainhub\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import AgentState, create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Evaluation Metrics Imports\n",
    "import krippendorff\n",
    "from bert_score import score as bert_score\n",
    "from ragas.metrics import answer_relevancy\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749286a-1690-4e5b-8f08-42afb623c5a5",
   "metadata": {},
   "source": [
    "### RAG Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89171057-9465-4cd4-974b-06f4875f7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG System Initialized.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openAI_embed = OpenAIEmbeddings(model=\"text-embedding-3-large\") #\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"CleanCorpus.csv\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents, \n",
    "    embedding=openAI_embed,\n",
    "    collection_name=\"plantCorpus_langchain\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "## Role and Goal\n",
    "You are an expert landscaping and agricultural assistant with deep, practical knowledge of the Indo-Gangetic plains. Your goal is to provide accurate, specific answers to user queries about plants.\n",
    "\n",
    "## Source of Truth: Plant Corpus\n",
    "You will be given context from a specialized `Plant Corpus`. This corpus is your **single source of truth** for all plant-specific data.\n",
    "\n",
    "### Retrieved Context:\n",
    "{corpus_content}\n",
    "\n",
    "## Core Instructions and Rules\n",
    "\n",
    "1.  **Prioritize Context:** You MUST base all plant facts, recommendations, and data **directly** on the provided `Plant Corpus` context. Do not use your general knowledge if it conflicts with the context.\n",
    "\n",
    "2.  **Synthesize, Don't Just Repeat:** When answering, intelligently synthesize information from the context's fields. For example, to answer \"what plant should I grow,\" you MUST combine `Climate Requirements`, `Soil Type`, and `Water Needs` to explain *why* a plant is suitable.\n",
    "\n",
    "3.  **Handle Missing Information (Critical):** If the user asks about a plant, region, or topic that is **not** in the provided context, you MUST clearly state that the information is not available in your specialized corpus. However, you can use your general knowledge to invent an answer for a plant not in list.\n",
    "\n",
    "4.  **Use Your Persona:** After you have provided the core facts *from the corpus*, you may add a brief, practical tip based on your persona (e.g., \"In my experience on the plains, this plant also helps with soil erosion,\" or \"Be sure to protect it from...\").\n",
    "\n",
    "5.  **Corpus Structure (For Your Reference):**\n",
    "    `Plant ID`, `Common Name`, `Scientific Name`, `Local Name (If Applicable)`, `Region`, `Climate Requirements`, `Soil Type`, `Sun Light Needs`, `Water Needs`, `Growth Rate`, `Ecological Role`, `Traditional Uses`\n",
    "\"\"\"\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    user_query = request.state[\"messages\"][-1].text\n",
    "    corpus_context = vector_store.similarity_search(query=user_query)\n",
    "\n",
    "    corpus_content = \"\\n\".join(doc.page_content for doc in corpus_context)\n",
    "\n",
    "    system_message = SYSTEM_PROMPT_TEMPLATE.format(corpus_content=corpus_content)\n",
    "    return system_message\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context]) \n",
    "\n",
    "noRAG_agent = create_agent(model, tools=[], middleware=[]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00bbd5a4-be47-4f1a-aecf-5a9f607a8dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested 25 documents into ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "df_corpus = pd.read_csv(\"Corpus.csv\")\n",
    "df_corpus = df_corpus.fillna(\"NaN\")\n",
    "df_corpus.to_csv(\"CleanCorpus.csv\")\n",
    "\n",
    "openAI_embed = OpenAIEmbeddings(model=\"text-embedding-3-large\") \n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"CleanCorpus.csv\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents, \n",
    "    embedding=openAI_embed,\n",
    "    collection_name=\"plantCorpus_langchain\"\n",
    ")\n",
    "\n",
    "print(f\"Ingested {len(documents)} documents into ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7a119-9d07-4314-af9d-795b07379876",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_personas = {\n",
    "    \"Evaluator_1_Landscape_Architect\": (\n",
    "        \"You are a Senior Landscape Architect for US Embassies. \"\n",
    "        \"You prioritize aesthetics, formal structure, and low maintenance. \"\n",
    "        \"You are strict about visual appeal and infrastructure safety.\"\n",
    "    ),\n",
    "    \"Evaluator_2_Local_Botanist\": (\n",
    "        \"You are a PhD Botanist specializing in the Indo-Gangetic Plain. \"\n",
    "        \"You care deeply about scientific accuracy, correct Latin names, \"\n",
    "        \"and specific soil/climate requirements. You dislike vague answers.\"\n",
    "    ),\n",
    "    \"Evaluator_3_Cultural_Historian\": (\n",
    "        \"You are an expert in Indian Ethnobotany and Folklore. \"\n",
    "        \"You focus on cultural relevance, traditional uses (Ayurveda), \"\n",
    "        \"and local naming conventions. You want to see cultural depth.\"\n",
    "    ),\n",
    "    \"Evaluator_4_Sustainability_Officer\": (\n",
    "        \"You are a Sustainability Officer focused on water conservation. \"\n",
    "        \"You heavily penalize plants that require too much water or fertilizer. \"\n",
    "        \"You prioritize ecological suitability and native species.\"\n",
    "    ),\n",
    "    \"Evaluator_5_General_Resident\": (\n",
    "        \"You are a homeowner in the region with average gardening skills. \"\n",
    "        \"You care about 'Overall Helpfulness' and simple, clear advice. \"\n",
    "        \"You find overly technical jargon unhelpful.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def get_evaluation(judge_persona, user_query, model_response):\n",
    "    system_prompt = f\"\"\"\n",
    "    {judge_persona}\n",
    "    \n",
    "    You are evaluating an AI assistant's response to a user query about plants in the Indo-Gangetic Plains.\n",
    "    \n",
    "    Please rate the response on these 4 metrics using a 1-5 Likert Scale:\n",
    "    1. Factual Accuracy (1=Hallucinated/Wrong, 5=Highly Accurate/Cited)\n",
    "    2. Ecological Suitability (1=Invasive/Deadly, 5=Perfect for Region)\n",
    "    3. Cultural Relevance (1=Generic/Ignorant, 5=Culturally Insightful/Local Context)\n",
    "    4. Overall Helpfulness (1=Useless, 5=Very Helpful)\n",
    "    \n",
    "    RETURN JSON ONLY in this format:\n",
    "    {{\n",
    "        \"Factual_Accuracy\": int,\n",
    "        \"Ecological_Suitability\": int,\n",
    "        \"Cultural_Relevance\": int,\n",
    "        \"Overall_Helpfulness\": int,\n",
    "        \"Reasoning\": \"Short explanation (max 1 sentence)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    user_content = f\"\"\"USER QUERY = {user_query}\n",
    "                    AI RESPONSE = {model_response}\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_content)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = model.invoke(messages)\n",
    "        content_str = response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        return json.loads(content_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820e622c-71e6-4629-b2e8-463790ed477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: rag.json or norag.json not found. Evaluation loop will fail.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"rag.json\", 'r', encoding=\"utf-8\") as rag_file:\n",
    "        rag_data = json.load(rag_file)\n",
    "    with open(\"norag.json\", 'r', encoding=\"utf-8\") as norag_file:\n",
    "        norag_data = json.load(norag_file)\n",
    "    print(f\"Loaded {len(rag_data)} RAG responses and {len(norag_data)} NoRAG responses.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"rag.json or norag.json not found\")\n",
    "    rag_data, norag_data = [], []\n",
    "\n",
    "results = []\n",
    "if rag_data and norag_data:\n",
    "    for i, (rag_item, norag_item) in enumerate(zip(rag_data, norag_data)):\n",
    "        query = rag_item['query']\n",
    "        rag_response = rag_item['response']\n",
    "        norag_response = norag_item['response']\n",
    "\n",
    "        if rag_item['query'] != norag_item['query']:\n",
    "            print(f\"Warning: Mismatch in queries at index {i}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Evaluating Query {i+1}/{len(rag_data)}\")\n",
    "\n",
    "        for evaluator_name, persona_prompt in evaluator_personas.items():\n",
    "            rag_grade = get_evaluation(persona_prompt, query, rag_response)\n",
    "            if rag_grade:\n",
    "                results.append({\n",
    "                    \"Query_ID\": i+1,\n",
    "                    \"System\": \"RAG\",\n",
    "                    \"Evaluator\": evaluator_name,\n",
    "                    **rag_grade \n",
    "                })\n",
    "            \n",
    "            norag_grade = get_evaluation(persona_prompt, query, norag_response)\n",
    "            if norag_grade:\n",
    "                results.append({\n",
    "                    \"Query_ID\": i+1,\n",
    "                    \"System\": \"No-RAG\",\n",
    "                    \"Evaluator\": evaluator_name,\n",
    "                    **norag_grade \n",
    "                })\n",
    "        time.sleep(1)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(\"evaluation_results.csv\", index=False)\n",
    "    print(\"Evaluation Complete. Saved to evaluation_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be5c638-8899-4042-ace0-10758b150d69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INTER-RATER RELIABILITY (Krippendorff's Alpha) ===\n",
      "Factual_Accuracy         : 0.7535\n",
      "Ecological_Suitability   : 0.8050\n",
      "Cultural_Relevance       : 0.8399\n",
      "Overall_Helpfulness      : 0.8260\n",
      "\n",
      "=== BERTScore (Semantic Divergence) ===\n",
      "\n",
      "=== RAGAS (Answer Relevancy) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907b44a857c948b9a774779c6115e6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     42\u001b[39m ragas_embeddings = OpenAIEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m ragas_dataset = Dataset.from_dict({\n\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m: df_rag[\u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m].tolist(),\n\u001b[32m     46\u001b[39m     \u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m: df_rag[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m].tolist(),\n\u001b[32m     47\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m'\u001b[39m: [[\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_rag))] \u001b[38;5;66;03m# Contexts required by RAGAS schema\u001b[39;00m\n\u001b[32m     48\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m ragas_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragas_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpt4_llm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragas_embeddings\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m df_rag[\u001b[33m'\u001b[39m\u001b[33mRagas_Relevancy\u001b[39m\u001b[33m'\u001b[39m] = ragas_results[\u001b[33m'\u001b[39m\u001b[33manswer_relevancy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvg Relevancy Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_rag[\u001b[33m'\u001b[39m\u001b[33mRagas_Relevancy\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\_analytics.py:278\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    277\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\evaluation.py:470\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar, return_executor, allow_nest_asyncio)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Default behavior: use nest_asyncio for backward compatibility (Jupyter notebooks)\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_async_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\async_utils.py:156\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(async_func, allow_nest_asyncio)\u001b[39m\n\u001b[32m    148\u001b[39m     loop_type = \u001b[38;5;28mtype\u001b[39m(loop).\u001b[34m__name__\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    150\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot execute nested async code with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloop_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    151\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muvloop does not support nested event loop execution. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    152\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease use asyncio\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms standard event loop in Jupyter environments, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mor refactor your code to avoid nested async calls.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\nest_asyncio.py:133\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m curr_task = curr_tasks.pop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\asyncio\\events.py:89\u001b[39m, in \u001b[36mHandle._run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\asyncio\\tasks.py:386\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m.__step(exc)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    380\u001b[39m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[32m    381\u001b[39m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\asyncio\\tasks.py:293\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(self, exc)\u001b[39m\n\u001b[32m    291\u001b[39m _enter_task(\u001b[38;5;28mself\u001b[39m._loop, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__step_run_and_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    295\u001b[39m     _leave_task(\u001b[38;5;28mself\u001b[39m._loop, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\asyncio\\tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\async_utils.py:77\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\executor.py:69\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(*args, **kwargs) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Any]:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     70\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\base.py:481\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    474\u001b[39m rm, group_cm = new_group(\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    476\u001b[39m     inputs=sample.to_dict(),\n\u001b[32m    477\u001b[39m     callbacks=callbacks,\n\u001b[32m    478\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.METRIC},\n\u001b[32m    479\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     score = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    482\u001b[39m         \u001b[38;5;28mself\u001b[39m._single_turn_ascore(sample=sample, callbacks=group_cm),\n\u001b[32m    483\u001b[39m         timeout=timeout,\n\u001b[32m    484\u001b[39m     )\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\asyncio\\tasks.py:507\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:135\u001b[39m, in \u001b[36mResponseRelevancy._single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_single_turn_ascore\u001b[39m(\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m, sample: SingleTurnSample, callbacks: Callbacks\n\u001b[32m    133\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    134\u001b[39m     row = sample.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:151\u001b[39m, in \u001b[36mAnswerRelevancy._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ascore\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: t.Dict, callbacks: Callbacks) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:146\u001b[39m, in \u001b[36mResponseRelevancy._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    140\u001b[39m prompt_input = ResponseRelevanceInput(response=row[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    142\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.question_generation.generate_multiple(\n\u001b[32m    143\u001b[39m     data=prompt_input, llm=\u001b[38;5;28mself\u001b[39m.llm, callbacks=callbacks, n=\u001b[38;5;28mself\u001b[39m.strictness\n\u001b[32m    144\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:126\u001b[39m, in \u001b[36mResponseRelevancy._calculate_score\u001b[39m\u001b[34m(self, answers, row)\u001b[39m\n\u001b[32m    124\u001b[39m     score = np.nan\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     cosine_sim = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     score = cosine_sim.mean() * \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m all_noncommittal)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:102\u001b[39m, in \u001b[36mResponseRelevancy.calculate_similarity\u001b[39m\u001b[34m(self, question, generated_questions)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m     98\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requires embeddings to be set.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m )\n\u001b[32m    100\u001b[39m question_vec = np.asarray(\u001b[38;5;28mself\u001b[39m.embeddings.embed_query(question)).reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    101\u001b[39m gen_question_vec = np.asarray(\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_questions\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    103\u001b[39m ).reshape(\u001b[38;5;28mlen\u001b[39m(generated_questions), -\u001b[32m1\u001b[39m)\n\u001b[32m    104\u001b[39m norm = np.linalg.norm(gen_question_vec, axis=\u001b[32m1\u001b[39m) * np.linalg.norm(\n\u001b[32m    105\u001b[39m     question_vec, axis=\u001b[32m1\u001b[39m\n\u001b[32m    106\u001b[39m )\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    108\u001b[39m     np.dot(gen_question_vec, question_vec.T).reshape(\n\u001b[32m    109\u001b[39m         -\u001b[32m1\u001b[39m,\n\u001b[32m    110\u001b[39m     )\n\u001b[32m    111\u001b[39m     / norm\n\u001b[32m    112\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\embeddings\\base.py:310\u001b[39m, in \u001b[36mLangchainEmbeddingsWrapper.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    307\u001b[39m result = \u001b[38;5;28mself\u001b[39m.embeddings.embed_documents(texts)\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Track usage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbeddingUsageEvent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlangchain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlegacy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_requests\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_async\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\_analytics.py:63\u001b[39m, in \u001b[36msilent.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _usage_event_debugging():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\ragas\\_analytics.py:233\u001b[39m, in \u001b[36mtrack\u001b[39m\u001b[34m(event_properties)\u001b[39m\n\u001b[32m    230\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mTracking Payload: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, payload)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUSAGE_TRACKING_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSAGE_REQUESTS_TIMEOUT_SEC\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\connection.py:741\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    739\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    761\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\connection.py:920\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    918\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml_prep\\testenv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:438\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ca_certs \u001b[38;5;129;01mor\u001b[39;00m ca_cert_dir \u001b[38;5;129;01mor\u001b[39;00m ca_cert_data:\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m         \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    440\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[16]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[32]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[33]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[34]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[35]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[36]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[37]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[38]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[39]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[40]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[41]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[42]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[43]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[44]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[45]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[46]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[47]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[48]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[49]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[50]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[51]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[52]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[53]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[54]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[55]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[56]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[57]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[58]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[59]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[60]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[61]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[62]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[18]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[63]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[64]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[65]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[66]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[67]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[68]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[69]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[70]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[71]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[72]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[73]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[74]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[75]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[76]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[77]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[78]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[79]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[80]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[81]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[82]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[83]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[84]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[85]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[86]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[87]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[88]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[89]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[90]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[91]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[92]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[93]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[94]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[95]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[96]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[97]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[98]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[19]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[29]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[23]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[17]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[21]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[24]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[26]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[99]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[25]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[22]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[30]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[31]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[27]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[20]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "Exception raised in Job[28]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.read_csv(\"evaluation_results.csv\")\n",
    "with open(\"ragList.json\", 'r', encoding=\"utf-8\") as rag_file:\n",
    "        rag_data = json.load(rag_file)\n",
    "with open(\"nonragList.json\", 'r', encoding=\"utf-8\") as norag_file:\n",
    "        nonrag_data = json.load(norag_file)\n",
    "\n",
    "# Krippendorff's Alpha\n",
    "if not df_results.empty:\n",
    "    print(\"\\n=== INTER-RATER RELIABILITY (Krippendorff's Alpha) ===\")\n",
    "    metrics = [\"Factual_Accuracy\", \"Ecological_Suitability\", \"Cultural_Relevance\", \"Overall_Helpfulness\"]\n",
    "    df_results['Response_ID'] = df_results['Query_ID'].astype(str) + \"_\" + df_results['System']\n",
    "\n",
    "    for metric in metrics:\n",
    "        try:\n",
    "            pivot_table = df_results.pivot(index='Response_ID', columns='Evaluator', values=metric)\n",
    "            reliability_data = pivot_table.transpose().to_numpy()\n",
    "            alpha = krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='ordinal')\n",
    "            print(f\"{metric:<25}: {alpha:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not calculate alpha for {metric}: {e}\")\n",
    "\n",
    "# BERTScore\n",
    "df_rag = pd.DataFrame(rag_data)\n",
    "df_norag = pd.DataFrame(norag_data)\n",
    "print(\"\\n=== BERTScore (Semantic Divergence) ===\")\n",
    "if rag_data and norag_data:\n",
    "    df_rag = pd.DataFrame(rag_data)\n",
    "    df_norag = pd.DataFrame(norag_data)\n",
    "\n",
    "    P, R, F1 = bert_score(\n",
    "        df_rag['response'].to_list(),\n",
    "        df_norag['response'].to_list(),\n",
    "        lang=\"eng\",\n",
    "        verbose=False\n",
    "    )\n",
    "    df_rag['BERTScore_Similarity'] = F1.numpy()\n",
    "    print(f\"Avg Similarity to Base Model: {df_rag['BERTScore_Similarity'].mean():.3f}\")\n",
    "\n",
    "# RAGAS\n",
    "print(\"\\n=== RAGAS (Answer Relevancy) ===\")\n",
    "if rag_data:\n",
    "    gpt4_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    ragas_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    ragas_dataset = Dataset.from_dict({\n",
    "        'question': df_rag['query'].tolist(),\n",
    "        'answer': df_rag['response'].tolist(),\n",
    "        'contexts': [[''] for _ in range(len(df_rag))]\n",
    "    })\n",
    "\n",
    "    ragas_results = evaluate(\n",
    "        dataset=ragas_dataset, \n",
    "        metrics=[answer_relevancy], \n",
    "        llm=gpt4_llm, \n",
    "        embeddings=ragas_embeddings\n",
    "    )\n",
    "\n",
    "    df_rag['Ragas_Relevancy'] = ragas_results['answer_relevancy']\n",
    "    print(f\"Avg Relevancy Score: {df_rag['Ragas_Relevancy'].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
